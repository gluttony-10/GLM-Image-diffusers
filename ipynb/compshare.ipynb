{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fab4ab6-be4b-4206-ba12-8dad73bac833",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 云端一键脚本 By bilibili@十字鱼\n",
    "- 十字鱼 https://space.bilibili.com/893892"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff4a71-531e-4c60-b762-6692fc36897b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.安装并运行\n",
    "- 如果启动不成功，请停止后重复运行第1步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4d5bf-b5ce-4e5e-91e4-814f142a5f49",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "os.environ[\"PATH\"]=\"/usr/local/miniconda3/envs/glut/bin:/usr/local/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ffmpeg/bin:/usr/local/cuda/bin\"\n",
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "os.environ[\"MPLBACKEND\"]=\"agg\"\n",
    "#安装目录\n",
    "path = \"/workspace\"\n",
    "#安装网址\n",
    "url = \"https://github.com/gluttony-10/GLM-Image-diffusers\"\n",
    "repo = url.split('/')[-1]\n",
    "#是否重装\n",
    "reinstall = False\n",
    "#修改分支\n",
    "branch = \"main\"\n",
    "#模型文件\n",
    "model_urls = \"\"\"\n",
    "\"\"\"\n",
    "#额外文件（先换行，再加链接）（下载到安装目录，方便剪切）\n",
    "extra_urls = \"\"\"\n",
    "https://modelscope.cn/models/Gluttony10/whl/resolve/master/torch-2.8.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl\n",
    "https://modelscope.cn/models/Gluttony10/whl/resolve/master/torchaudio-2.8.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl\n",
    "https://modelscope.cn/models/Gluttony10/whl/resolve/master/torchvision-0.23.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl\n",
    "\"\"\"\n",
    "#下载文件2（不要修改）\n",
    "def download_2():\n",
    "    tasks = []\n",
    "    tasks.extend(download_aria(extra_urls,f'{path}/{repo}'))\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for task in tasks:\n",
    "            executor.submit(os.system, task)\n",
    "    print('文件下载完毕')\n",
    "#下载模块（不要修改）\n",
    "def download_aria(links,folder):\n",
    "    tasks = []\n",
    "    link = links.strip().split(\"\\n\")\n",
    "    for li in link:\n",
    "        if \"?download=true\" in li:\n",
    "            li = li.replace(\"?download=true\",\"\")\n",
    "        if \"https://ghfast.top/https://github.com\" in li:\n",
    "            li=li.replace(\"https://ghfast.top.com/https://github.com\",\"https://ghfast.top/https://github.com\")\n",
    "        elif \"https://github.com\" in li:\n",
    "            li=li.replace(\"https://github.com\",\"https://ghfast.top/https://github.com\")\n",
    "        elif \"huggingface.co\" in li:\n",
    "            li=li.replace(\"huggingface.co\",\"hf-mirror.com\")\n",
    "        elif \"civitai.com\" in li:\n",
    "            li=li.replace(\"civitai.com\",\"civitai.sukaka.top\")\n",
    "        fi = li.split('/')[-1]\n",
    "        if \".\" in fi:\n",
    "            tasks.append(f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -t 10 -d {folder} -o {fi} \"{li}\"')\n",
    "        else:\n",
    "            tasks.append(f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -t 10 -d {folder} \"{li}\"')\n",
    "    return tasks\n",
    "#主进程（不要修改）\n",
    "def main():\n",
    "    time_start = time.time()\n",
    "    print(\"运行开始\")\n",
    "    !df -hl #查看磁盘\n",
    "    !nvidia-smi #查看显卡\n",
    "    %cd {path}\n",
    "    if reinstall:\n",
    "        print('旧文件删除中')\n",
    "        !rm -rf {path}/{repo}\n",
    "    print(f'开始安装{repo}')\n",
    "    !apt-get update\n",
    "    !apt-get install -y git aria2 build-essential nvtop ffmpeg nano\n",
    "    !conda config --remove-key channels\n",
    "    !conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge\n",
    "    !conda create -n glut python=3.12 -y\n",
    "    !git config --global http.postBuffer 2000003072\n",
    "    !git -C {path} clone {url} --recursive\n",
    "    if os.path.exists(f'{path}/{repo}'):\n",
    "        !git -C {path}/{repo} checkout {branch}\n",
    "        !git -C {path}/{repo} pull\n",
    "        !git -C {path}/{repo} submodule init\n",
    "        !git -C {path}/{repo} submodule update\n",
    "        %cd {path}/{repo}\n",
    "        download_2()\n",
    "        !pip install torch-2.8.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl torchaudio-2.8.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl torchvision-0.23.0%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl\n",
    "        !pip install --no-build-isolation ninja setuptools wheel cython modelscope huggingface-hub hf_xet pyarmor nvitop -U\n",
    "        !pip install --no-build-isolation git+https://github.com/huggingface/diffusers --force-reinstall\n",
    "        !pip install --no-build-isolation git+https://github.com/huggingface/transformers --force-reinstall\n",
    "        !pip install --no-build-isolation -r requirements.txt\n",
    "        !modelscope download --model Gluttony10/GLM-Image-diffusers --local_dir ./models/GLM-Image-diffusers\n",
    "        time_end = time.time()\n",
    "        print('\\033[32m安装耗时:',int((time_end - time_start)/60),'min\\033[0m')\n",
    "        !HF_ENDPOINT=https://hf-mirror.com python glut.py --server_name \"0.0.0.0\" --server_port 7860\n",
    "    else:\n",
    "        print('安装失败请重试')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b91811",
   "metadata": {},
   "source": [
    "## 2.快速启动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a741b9e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"]=\"/usr/local/miniconda3/envs/glut/bin:/usr/local/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ffmpeg/bin:/usr/local/cuda/bin\"\n",
    "os.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"\n",
    "os.environ[\"MPLBACKEND\"]=\"agg\"\n",
    "!df -hl #查看磁盘\n",
    "%cd /workspace/GLM-Image-diffusers\n",
    "!HF_ENDPOINT=https://hf-mirror.com python glut.py --server_name \"0.0.0.0\" --server_port 7860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7658e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"]=\"/usr/local/miniconda3/envs/glut/bin:/usr/local/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ffmpeg/bin:/usr/local/cuda/bin\"\n",
    "path = \"/workspace\"\n",
    "url = \"https://github.com/gluttony-10/GLM-Image-diffusers\"\n",
    "repo = url.split('/')[-1]\n",
    "%cd {path}/{repo}\n",
    "!rm -rf {path}/{repo}/pyarmor_runtime_000000\n",
    "!pyarmor gen {path}/{repo}/glut.py\n",
    "!rm -rf {path}/{repo}/glut.py\n",
    "!mv {path}/{repo}/dist/pyarmor_runtime_000000 {path}/{repo}\n",
    "!mv {path}/{repo}/dist/glut.py {path}/{repo}\n",
    "!rm -rf {path}/{repo}/dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6294be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "export PATH=\"/usr/local/miniconda3/envs/glut/bin:/usr/local/miniconda3/condabin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ffmpeg/bin:/usr/local/cuda/bin\"\n",
    "export HF_ENDPOINT=\"https://hf-mirror.com\"\n",
    "export MPLBACKEND=\"agg\"\n",
    "cd /workspace/GLM-Image-diffusers\n",
    "python glut.py --server_name \"0.0.0.0\" --server_port 7860 > log.txt 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a15518",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /workspace/s.sh /start.d\n",
    "!chmod +x /start.d/s.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
